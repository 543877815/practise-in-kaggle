{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question from: https://www.kaggle.com/c/street-view-getting-started-with-julia/data/\n",
    "\n",
    "solution from: https://nbviewer.jupyter.org/github/erhwenkuo/deep-learning-with-keras-notebooks/blob/master/2.0-first-steps-with-julia.ipynb\n",
    "\n",
    "submission: https://www.kaggle.com/c/street-view-getting-started-with-julia/submit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料預處理 (Data Preprocessing)\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imsave, imresize  # scipy==1.1.0\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  (6283, 32, 32)\n",
      "After:  (6283, 32, 32, 1)\n",
      "Before:  (6220, 32, 32)\n",
      "After:  (6220, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# 圖像資料的檔案路徑\n",
    "path = \"data\"\n",
    "\n",
    "# 圖像轉換後的目標大小 (32像素 x 32像素)\n",
    "img_height, img_width = 32, 32\n",
    "\n",
    "# 轉換圖像後的儲存目錄\n",
    "suffix = \"Preproc\"\n",
    "trainDataPath = path + \"/train\" + suffix\n",
    "testDataPath = path + \"/test\" + suffix\n",
    "\n",
    "# 產生目錄\n",
    "if not os.path.exists(trainDataPath):\n",
    "    os.makedirs(trainDataPath)\n",
    "\n",
    "if not os.path.exists(testDataPath):\n",
    "    os.makedirs(testDataPath)\n",
    "    \n",
    "### 圖像大小與圖像的色彩的預處理 ###\n",
    "\n",
    "for datasetType in [\"train\",\"test\"]:\n",
    "    # 透過natsorted可以讓回傳的檔案名稱的排序\n",
    "    imgFiles = natsorted(glob.glob(path + \"/\" + datasetType + \"/*\"))\n",
    "    \n",
    "    # 初始一個ndarray物件來暫存讀進來的圖像資料\n",
    "    imgData = np.zeros((len(imgFiles), img_height, img_width))\n",
    "    \n",
    "    # 使用迴圈來處理每一筆圖像檔\n",
    "    for i, imgFilePath in enumerate(imgFiles):\n",
    "        # 圖像的色彩 (Image Color)處理\n",
    "        img = imread(imgFilePath, True) # True: 代表讀取圖像時順便將多階圖像, 打平成灰階(單一通道:one channel)\n",
    "        \n",
    "        # 圖像大小的修改 (Image Resizing)\n",
    "        imgResized = imresize(img, (img_height, img_width))\n",
    "        \n",
    "        # 把圖像資料儲放在暫存記憶體中\n",
    "        imgData[i] = imgResized\n",
    "        \n",
    "        # 將修改的圖像儲存到檔案系統 (方便視覺化了解)\n",
    "        filename = os.path.basename(imgFilePath)\n",
    "        filenameDotSplit = filename.split(\".\")\n",
    "        newFilename = str(int(filenameDotSplit[0])).zfill(5) + \".\" + filenameDotSplit[-1].lower()\n",
    "        newFilepath = path + \"/\" + datasetType + suffix + \"/\" + newFilename\n",
    "        imsave(newFilepath, imgResized)\n",
    "    \n",
    "    # 新增加\"Channel\"的維度\n",
    "    print(\"Before: \", imgData.shape)\n",
    "    imgData = imgData[:,:,:,np.newaxis] # 改變前: []\n",
    "    print(\"After: \", imgData.shape)\n",
    "    \n",
    "    # 進行資料(pixel值)標準化\n",
    "    imgData = imgData.astype('float32')/255\n",
    "    \n",
    "    # 以numpy物件將圖像轉換後的ndarray物件保存在檔案系統中\n",
    "    np.save(path + \"/\" + datasetType + suffix + \".npy\", imgData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 標籤轉換 (Label Conversion)\n",
    "import keras\n",
    "\n",
    "def label2int(ch):\n",
    "    asciiVal = ord(ch)\n",
    "    if(asciiVal<=57): #0-9\n",
    "        asciiVal-=48\n",
    "    elif(asciiVal<=90): #A-Z\n",
    "        asciiVal-=55\n",
    "    else: #a-z\n",
    "        asciiVal-=61\n",
    "    return asciiVal\n",
    "    \n",
    "def int2label(i):\n",
    "    if(i<=9): #0-9\n",
    "        i+=48\n",
    "    elif(i<=35): #A-Z\n",
    "        i+=55\n",
    "    else: #a-z\n",
    "        i+=61\n",
    "    return chr(i)\n",
    "\n",
    "# 圖像資料的檔案路徑\n",
    "path = \"data\"\n",
    "\n",
    "# 載入標籤資料\n",
    "y_train = pd.read_csv(path + \"/trainLabels.csv\").values[:,1] #只保留\"標籤資料\"欄\n",
    "\n",
    "# 對標籤(Label)進行one-hot編碼\n",
    "Y_train = np.zeros((y_train.shape[0], 62)) # A-Z, a-z, 0-9共有62個類別\n",
    "\n",
    "for i in range(y_train.shape[0]):\n",
    "    Y_train[i][label2int(y_train[i])] = 1 # One-hot\n",
    "\n",
    "# 把轉換過的標籤(Label)資料保存在檔案系統便於後續的快速載入與處理\n",
    "np.save(path + \"/\" + \"labelsPreproc.npy\", Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "batch_size = 128 # 訓練批次量 (Batch Size)\n",
    "nb_classes = 62  # A-Z, a-z, 0-9共有62個類別\n",
    "nb_epoch = 500   # 進行500個訓練循環\n",
    "\n",
    "# Input image dimensions\n",
    "# 要輸入到第一層網絡的圖像大小 (32像素 x 32像素)\n",
    "img_height, img_width = 32, 32\n",
    "\n",
    "# 相關資料的路徑\n",
    "path = \"data/\"\n",
    "\n",
    "# 載入預處理好的訓練資料與標籤\n",
    "X_train_all = np.load(path+\"/trainPreproc.npy\")\n",
    "Y_train_all = np.load(path+\"/labelsPreproc.npy\")\n",
    "\n",
    "# 將資料區分為訓練資料集與驗證資料集\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_all, Y_train_all, test_size=0.25, stratify=np.argmax(Y_train_all, axis=1))\n",
    "\n",
    "# 設定圖像增強(data augmentation)的設定\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.15,\n",
    "    height_shift_range = 0.15,\n",
    "    shear_range = 0.4,\n",
    "    zoom_range = 0.3,                    \n",
    "    channel_shift_range = 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 128)       1280      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 62)                254014    \n",
      "=================================================================\n",
      "Total params: 57,527,742\n",
      "Trainable params: 57,527,742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### 卷積網絡模型架構 ###\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(128,(3, 3), padding='same', kernel_initializer='he_normal', activation='relu', \n",
    "                        input_shape=(img_height, img_width, 1)))\n",
    "\n",
    "model.add(Convolution2D(128,(3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(256,(3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Convolution2D(256,(3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(512,(3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Convolution2D(512,(3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Convolution2D(512,(3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(4096, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes, kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "# 展現整個模型架構\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4712 samples, validate on 1571 samples\n",
      "Epoch 1/20\n",
      "4712/4712 [==============================] - 10s 2ms/step - loss: 4.7593 - accuracy: 0.0522 - val_loss: 3.7852 - val_accuracy: 0.0732\n",
      "Epoch 2/20\n",
      "4712/4712 [==============================] - 4s 812us/step - loss: 3.8036 - accuracy: 0.0688 - val_loss: 3.7772 - val_accuracy: 0.0732\n",
      "Epoch 3/20\n",
      "4712/4712 [==============================] - 4s 781us/step - loss: 3.8107 - accuracy: 0.0677 - val_loss: 3.7736 - val_accuracy: 0.0732\n",
      "Epoch 4/20\n",
      "4712/4712 [==============================] - 4s 748us/step - loss: 3.7920 - accuracy: 0.0666 - val_loss: 3.7420 - val_accuracy: 0.0732\n",
      "Epoch 5/20\n",
      "4712/4712 [==============================] - 4s 783us/step - loss: 3.7989 - accuracy: 0.0855 - val_loss: 3.7736 - val_accuracy: 0.0516\n",
      "Epoch 6/20\n",
      "4712/4712 [==============================] - 3s 735us/step - loss: 3.8169 - accuracy: 0.0906 - val_loss: 3.6618 - val_accuracy: 0.1770\n",
      "Epoch 7/20\n",
      "4712/4712 [==============================] - 4s 748us/step - loss: 3.3658 - accuracy: 0.1781 - val_loss: 2.8148 - val_accuracy: 0.2648\n",
      "Epoch 8/20\n",
      "4712/4712 [==============================] - 4s 783us/step - loss: 2.5927 - accuracy: 0.3421 - val_loss: 2.0685 - val_accuracy: 0.4952\n",
      "Epoch 9/20\n",
      "4712/4712 [==============================] - 4s 792us/step - loss: 2.0058 - accuracy: 0.4682 - val_loss: 1.5235 - val_accuracy: 0.5856\n",
      "Epoch 10/20\n",
      "4712/4712 [==============================] - 4s 782us/step - loss: 1.5355 - accuracy: 0.5745 - val_loss: 1.1742 - val_accuracy: 0.6575\n",
      "Epoch 11/20\n",
      "4712/4712 [==============================] - 4s 765us/step - loss: 1.2943 - accuracy: 0.6335 - val_loss: 1.0557 - val_accuracy: 0.7091\n",
      "Epoch 12/20\n",
      "4712/4712 [==============================] - 4s 759us/step - loss: 0.9642 - accuracy: 0.7199 - val_loss: 0.9762 - val_accuracy: 0.7104\n",
      "Epoch 13/20\n",
      "4712/4712 [==============================] - 4s 762us/step - loss: 0.8357 - accuracy: 0.7462 - val_loss: 1.0041 - val_accuracy: 0.7155\n",
      "Epoch 14/20\n",
      "4712/4712 [==============================] - 4s 780us/step - loss: 0.7209 - accuracy: 0.7765 - val_loss: 0.9461 - val_accuracy: 0.7212\n",
      "Epoch 15/20\n",
      "4712/4712 [==============================] - 3s 736us/step - loss: 0.5713 - accuracy: 0.8205 - val_loss: 0.8829 - val_accuracy: 0.7454\n",
      "Epoch 16/20\n",
      "4712/4712 [==============================] - 4s 759us/step - loss: 0.4536 - accuracy: 0.8540 - val_loss: 0.9367 - val_accuracy: 0.7307\n",
      "Epoch 17/20\n",
      "4712/4712 [==============================] - 4s 762us/step - loss: 0.4822 - accuracy: 0.8476 - val_loss: 0.8405 - val_accuracy: 0.7798\n",
      "Epoch 18/20\n",
      "4712/4712 [==============================] - 3s 735us/step - loss: 0.2831 - accuracy: 0.9056 - val_loss: 0.8793 - val_accuracy: 0.7721\n",
      "Epoch 19/20\n",
      "4712/4712 [==============================] - 5s 1ms/step - loss: 0.2432 - accuracy: 0.9149 - val_loss: 0.9563 - val_accuracy: 0.7518\n",
      "Epoch 20/20\n",
      "4712/4712 [==============================] - 4s 766us/step - loss: 0.2743 - accuracy: 0.9104 - val_loss: 1.2639 - val_accuracy: 0.7015\n",
      "Epoch 1/500\n",
      "37/36 [==============================] - 5s 122ms/step - loss: 2.1448 - accuracy: 0.4495 - val_loss: 0.8683 - val_accuracy: 0.7537\n",
      "Epoch 2/500\n",
      " 2/36 [>.............................] - ETA: 2s - loss: 1.6276 - accuracy: 0.5508"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/36 [==============================] - 3s 86ms/step - loss: 1.4589 - accuracy: 0.6023 - val_loss: 0.7870 - val_accuracy: 0.7817\n",
      "Epoch 3/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 1.2824 - accuracy: 0.6299 - val_loss: 0.7181 - val_accuracy: 0.7976\n",
      "Epoch 4/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 1.1889 - accuracy: 0.6577 - val_loss: 0.6966 - val_accuracy: 0.8065\n",
      "Epoch 5/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 1.0627 - accuracy: 0.6848 - val_loss: 0.6654 - val_accuracy: 0.8135\n",
      "Epoch 6/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 1.0054 - accuracy: 0.7035 - val_loss: 0.6669 - val_accuracy: 0.7944\n",
      "Epoch 7/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.9127 - accuracy: 0.7288 - val_loss: 0.6385 - val_accuracy: 0.8307\n",
      "Epoch 8/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.8623 - accuracy: 0.7337 - val_loss: 0.6646 - val_accuracy: 0.8211\n",
      "Epoch 9/500\n",
      "37/36 [==============================] - 4s 112ms/step - loss: 0.8642 - accuracy: 0.7349 - val_loss: 0.6437 - val_accuracy: 0.8020\n",
      "Epoch 10/500\n",
      "37/36 [==============================] - 4s 95ms/step - loss: 0.8095 - accuracy: 0.7513 - val_loss: 0.6548 - val_accuracy: 0.8186\n",
      "Epoch 11/500\n",
      "37/36 [==============================] - 3s 79ms/step - loss: 0.8000 - accuracy: 0.7562 - val_loss: 0.6502 - val_accuracy: 0.8071\n",
      "Epoch 12/500\n",
      "37/36 [==============================] - 3s 80ms/step - loss: 0.7404 - accuracy: 0.7693 - val_loss: 0.6258 - val_accuracy: 0.8224\n",
      "Epoch 13/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.7325 - accuracy: 0.7744 - val_loss: 0.6373 - val_accuracy: 0.8192\n",
      "Epoch 14/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.6812 - accuracy: 0.7876 - val_loss: 0.6302 - val_accuracy: 0.8300\n",
      "Epoch 15/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.6665 - accuracy: 0.7916 - val_loss: 0.6338 - val_accuracy: 0.8090\n",
      "Epoch 16/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.6460 - accuracy: 0.7954 - val_loss: 0.6238 - val_accuracy: 0.8281\n",
      "Epoch 17/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.6290 - accuracy: 0.7954 - val_loss: 0.6669 - val_accuracy: 0.8122\n",
      "Epoch 18/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.6211 - accuracy: 0.8007 - val_loss: 0.6333 - val_accuracy: 0.8307\n",
      "Epoch 19/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.6271 - accuracy: 0.8001 - val_loss: 0.6302 - val_accuracy: 0.8269\n",
      "Epoch 20/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.6061 - accuracy: 0.8037 - val_loss: 0.6036 - val_accuracy: 0.8421\n",
      "Epoch 21/500\n",
      "37/36 [==============================] - 3s 81ms/step - loss: 0.5571 - accuracy: 0.8149 - val_loss: 0.6268 - val_accuracy: 0.8339\n",
      "Epoch 22/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.5531 - accuracy: 0.8226 - val_loss: 0.6172 - val_accuracy: 0.8339\n",
      "Epoch 23/500\n",
      "37/36 [==============================] - 3s 94ms/step - loss: 0.5508 - accuracy: 0.8234 - val_loss: 0.6315 - val_accuracy: 0.8186\n",
      "Epoch 24/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.5054 - accuracy: 0.8319 - val_loss: 0.5904 - val_accuracy: 0.8370\n",
      "Epoch 25/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.5286 - accuracy: 0.8289 - val_loss: 0.6361 - val_accuracy: 0.8313\n",
      "Epoch 26/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.5350 - accuracy: 0.8283 - val_loss: 0.6212 - val_accuracy: 0.8345\n",
      "Epoch 27/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.4855 - accuracy: 0.8349 - val_loss: 0.6246 - val_accuracy: 0.8288\n",
      "Epoch 28/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.4862 - accuracy: 0.8410 - val_loss: 0.6176 - val_accuracy: 0.8326\n",
      "Epoch 29/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.4643 - accuracy: 0.8478 - val_loss: 0.6308 - val_accuracy: 0.8307\n",
      "Epoch 30/500\n",
      "37/36 [==============================] - 3s 94ms/step - loss: 0.4850 - accuracy: 0.8410 - val_loss: 0.5848 - val_accuracy: 0.8434\n",
      "Epoch 31/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.4376 - accuracy: 0.8461 - val_loss: 0.6621 - val_accuracy: 0.8288\n",
      "Epoch 32/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.4519 - accuracy: 0.8559 - val_loss: 0.6417 - val_accuracy: 0.8294\n",
      "Epoch 33/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.4167 - accuracy: 0.8623 - val_loss: 0.6580 - val_accuracy: 0.8281\n",
      "Epoch 34/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.4292 - accuracy: 0.8538 - val_loss: 0.6551 - val_accuracy: 0.8288\n",
      "Epoch 35/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.4290 - accuracy: 0.8587 - val_loss: 0.6560 - val_accuracy: 0.8269\n",
      "Epoch 36/500\n",
      "37/36 [==============================] - 4s 100ms/step - loss: 0.4115 - accuracy: 0.8640 - val_loss: 0.6867 - val_accuracy: 0.8370\n",
      "Epoch 37/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.4056 - accuracy: 0.8638 - val_loss: 0.6162 - val_accuracy: 0.8377\n",
      "Epoch 38/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.3877 - accuracy: 0.8682 - val_loss: 0.6440 - val_accuracy: 0.8383\n",
      "Epoch 39/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.3837 - accuracy: 0.8708 - val_loss: 0.6478 - val_accuracy: 0.8415\n",
      "Epoch 40/500\n",
      "37/36 [==============================] - 4s 95ms/step - loss: 0.3777 - accuracy: 0.8731 - val_loss: 0.6471 - val_accuracy: 0.8173\n",
      "Epoch 41/500\n",
      "37/36 [==============================] - 3s 81ms/step - loss: 0.3881 - accuracy: 0.8654 - val_loss: 0.6302 - val_accuracy: 0.8300\n",
      "Epoch 42/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.3921 - accuracy: 0.8691 - val_loss: 0.6099 - val_accuracy: 0.8447\n",
      "Epoch 43/500\n",
      "37/36 [==============================] - 4s 95ms/step - loss: 0.3602 - accuracy: 0.8809 - val_loss: 0.6405 - val_accuracy: 0.8281\n",
      "Epoch 44/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.3521 - accuracy: 0.8795 - val_loss: 0.7067 - val_accuracy: 0.8243\n",
      "Epoch 45/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.3307 - accuracy: 0.8882 - val_loss: 0.6347 - val_accuracy: 0.8351\n",
      "Epoch 46/500\n",
      "37/36 [==============================] - 4s 100ms/step - loss: 0.3557 - accuracy: 0.8816 - val_loss: 0.7076 - val_accuracy: 0.8440\n",
      "Epoch 47/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.3453 - accuracy: 0.8852 - val_loss: 0.6528 - val_accuracy: 0.8447\n",
      "Epoch 48/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.3318 - accuracy: 0.8922 - val_loss: 0.6373 - val_accuracy: 0.8466\n",
      "Epoch 49/500\n",
      "37/36 [==============================] - 3s 95ms/step - loss: 0.3268 - accuracy: 0.8888 - val_loss: 0.6954 - val_accuracy: 0.8377\n",
      "Epoch 50/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.3126 - accuracy: 0.8924 - val_loss: 0.6601 - val_accuracy: 0.8358\n",
      "Epoch 51/500\n",
      "37/36 [==============================] - 4s 95ms/step - loss: 0.3179 - accuracy: 0.8935 - val_loss: 0.7021 - val_accuracy: 0.8351\n",
      "Epoch 52/500\n",
      "37/36 [==============================] - 4s 95ms/step - loss: 0.3174 - accuracy: 0.8888 - val_loss: 0.6156 - val_accuracy: 0.8339\n",
      "Epoch 53/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.2972 - accuracy: 0.8958 - val_loss: 0.6760 - val_accuracy: 0.8440\n",
      "Epoch 54/500\n",
      "37/36 [==============================] - 3s 94ms/step - loss: 0.3091 - accuracy: 0.8933 - val_loss: 0.6765 - val_accuracy: 0.8313\n",
      "Epoch 55/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.2941 - accuracy: 0.8981 - val_loss: 0.6731 - val_accuracy: 0.8434\n",
      "Epoch 56/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.3008 - accuracy: 0.8986 - val_loss: 0.6589 - val_accuracy: 0.8326\n",
      "Epoch 57/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.2874 - accuracy: 0.8990 - val_loss: 0.6622 - val_accuracy: 0.8332\n",
      "Epoch 58/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.3046 - accuracy: 0.8988 - val_loss: 0.6994 - val_accuracy: 0.8345\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/36 [==============================] - 3s 94ms/step - loss: 0.2757 - accuracy: 0.9045 - val_loss: 0.6826 - val_accuracy: 0.8269\n",
      "Epoch 60/500\n",
      "37/36 [==============================] - 4s 95ms/step - loss: 0.2771 - accuracy: 0.9047 - val_loss: 0.6656 - val_accuracy: 0.8440\n",
      "Epoch 61/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.2759 - accuracy: 0.9051 - val_loss: 0.6575 - val_accuracy: 0.8351\n",
      "Epoch 62/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.2746 - accuracy: 0.9066 - val_loss: 0.6804 - val_accuracy: 0.8402\n",
      "Epoch 63/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.2632 - accuracy: 0.9068 - val_loss: 0.6861 - val_accuracy: 0.8402\n",
      "Epoch 64/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.2580 - accuracy: 0.9094 - val_loss: 0.7105 - val_accuracy: 0.8345\n",
      "Epoch 65/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.2695 - accuracy: 0.9075 - val_loss: 0.7047 - val_accuracy: 0.8288\n",
      "Epoch 66/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.2666 - accuracy: 0.9132 - val_loss: 0.7018 - val_accuracy: 0.8396\n",
      "Epoch 67/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.2668 - accuracy: 0.9022 - val_loss: 0.6762 - val_accuracy: 0.8421\n",
      "Epoch 68/500\n",
      "37/36 [==============================] - 4s 96ms/step - loss: 0.2758 - accuracy: 0.9107 - val_loss: 0.7244 - val_accuracy: 0.8275\n",
      "Epoch 69/500\n",
      "37/36 [==============================] - 4s 98ms/step - loss: 0.2600 - accuracy: 0.9087 - val_loss: 0.7355 - val_accuracy: 0.8218\n",
      "Epoch 70/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.2519 - accuracy: 0.9100 - val_loss: 0.7143 - val_accuracy: 0.8390\n",
      "Epoch 71/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.2561 - accuracy: 0.9138 - val_loss: 0.7134 - val_accuracy: 0.8498\n",
      "Epoch 72/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.2524 - accuracy: 0.9138 - val_loss: 0.6716 - val_accuracy: 0.8415\n",
      "Epoch 73/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.2299 - accuracy: 0.9200 - val_loss: 0.7273 - val_accuracy: 0.8364\n",
      "Epoch 74/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.2537 - accuracy: 0.9109 - val_loss: 0.6756 - val_accuracy: 0.8383\n",
      "Epoch 75/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.2491 - accuracy: 0.9166 - val_loss: 0.7313 - val_accuracy: 0.8447\n",
      "Epoch 76/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.2319 - accuracy: 0.9215 - val_loss: 0.7046 - val_accuracy: 0.8421\n",
      "Epoch 77/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.2307 - accuracy: 0.9221 - val_loss: 0.7106 - val_accuracy: 0.8383\n",
      "Epoch 78/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.2155 - accuracy: 0.9268 - val_loss: 0.7614 - val_accuracy: 0.8447\n",
      "Epoch 79/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.2305 - accuracy: 0.9200 - val_loss: 0.7146 - val_accuracy: 0.8300\n",
      "Epoch 80/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.2234 - accuracy: 0.9234 - val_loss: 0.7415 - val_accuracy: 0.8377\n",
      "Epoch 81/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.2136 - accuracy: 0.9261 - val_loss: 0.7266 - val_accuracy: 0.8409\n",
      "Epoch 82/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.2180 - accuracy: 0.9264 - val_loss: 0.7373 - val_accuracy: 0.8466\n",
      "Epoch 83/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.2238 - accuracy: 0.9236 - val_loss: 0.7417 - val_accuracy: 0.8332\n",
      "Epoch 84/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.2201 - accuracy: 0.9238 - val_loss: 0.7162 - val_accuracy: 0.8358\n",
      "Epoch 85/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.2058 - accuracy: 0.9283 - val_loss: 0.6821 - val_accuracy: 0.8472\n",
      "Epoch 86/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.2161 - accuracy: 0.9253 - val_loss: 0.7198 - val_accuracy: 0.8332\n",
      "Epoch 87/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.2201 - accuracy: 0.9230 - val_loss: 0.7303 - val_accuracy: 0.8415\n",
      "Epoch 88/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.2221 - accuracy: 0.9255 - val_loss: 0.7498 - val_accuracy: 0.8364\n",
      "Epoch 89/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.2325 - accuracy: 0.9189 - val_loss: 0.7046 - val_accuracy: 0.8453\n",
      "Epoch 90/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.1880 - accuracy: 0.9319 - val_loss: 0.7662 - val_accuracy: 0.8402\n",
      "Epoch 91/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.2013 - accuracy: 0.9285 - val_loss: 0.7552 - val_accuracy: 0.8294\n",
      "Epoch 92/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.2071 - accuracy: 0.9278 - val_loss: 0.7468 - val_accuracy: 0.8256\n",
      "Epoch 93/500\n",
      "37/36 [==============================] - 4s 95ms/step - loss: 0.1898 - accuracy: 0.9359 - val_loss: 0.7888 - val_accuracy: 0.8377\n",
      "Epoch 94/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.1972 - accuracy: 0.9302 - val_loss: 0.7805 - val_accuracy: 0.8415\n",
      "Epoch 95/500\n",
      "37/36 [==============================] - 4s 96ms/step - loss: 0.2062 - accuracy: 0.9315 - val_loss: 0.7703 - val_accuracy: 0.8421\n",
      "Epoch 96/500\n",
      "37/36 [==============================] - 3s 81ms/step - loss: 0.1867 - accuracy: 0.9325 - val_loss: 0.7964 - val_accuracy: 0.8409\n",
      "Epoch 97/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.1853 - accuracy: 0.9331 - val_loss: 0.7189 - val_accuracy: 0.8332\n",
      "Epoch 98/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.1812 - accuracy: 0.9351 - val_loss: 0.7992 - val_accuracy: 0.8421\n",
      "Epoch 99/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.1749 - accuracy: 0.9412 - val_loss: 0.7931 - val_accuracy: 0.8491\n",
      "Epoch 100/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.1752 - accuracy: 0.9419 - val_loss: 0.7969 - val_accuracy: 0.8390\n",
      "Epoch 101/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.1986 - accuracy: 0.9353 - val_loss: 0.7826 - val_accuracy: 0.8320\n",
      "Epoch 102/500\n",
      "37/36 [==============================] - 3s 79ms/step - loss: 0.1720 - accuracy: 0.9406 - val_loss: 0.7817 - val_accuracy: 0.8377\n",
      "Epoch 103/500\n",
      "37/36 [==============================] - 4s 97ms/step - loss: 0.1929 - accuracy: 0.9338 - val_loss: 0.7066 - val_accuracy: 0.8447\n",
      "Epoch 104/500\n",
      "37/36 [==============================] - 3s 94ms/step - loss: 0.1803 - accuracy: 0.9387 - val_loss: 0.7311 - val_accuracy: 0.8390\n",
      "Epoch 105/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.1834 - accuracy: 0.9355 - val_loss: 0.7930 - val_accuracy: 0.8409\n",
      "Epoch 106/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.1799 - accuracy: 0.9380 - val_loss: 0.7836 - val_accuracy: 0.8440\n",
      "Epoch 107/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.1828 - accuracy: 0.9365 - val_loss: 0.8413 - val_accuracy: 0.8345\n",
      "Epoch 108/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.1739 - accuracy: 0.9357 - val_loss: 0.8729 - val_accuracy: 0.8491\n",
      "Epoch 109/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.1783 - accuracy: 0.9410 - val_loss: 0.7621 - val_accuracy: 0.8409\n",
      "Epoch 110/500\n",
      "37/36 [==============================] - 4s 102ms/step - loss: 0.1700 - accuracy: 0.9442 - val_loss: 0.8130 - val_accuracy: 0.8383\n",
      "Epoch 111/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.1703 - accuracy: 0.9421 - val_loss: 0.7875 - val_accuracy: 0.8339\n",
      "Epoch 112/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.1688 - accuracy: 0.9444 - val_loss: 0.8150 - val_accuracy: 0.8402\n",
      "Epoch 113/500\n",
      "37/36 [==============================] - 3s 78ms/step - loss: 0.1513 - accuracy: 0.9450 - val_loss: 0.8033 - val_accuracy: 0.8377\n",
      "Epoch 114/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.1818 - accuracy: 0.9385 - val_loss: 0.7648 - val_accuracy: 0.8288\n",
      "Epoch 115/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.1744 - accuracy: 0.9410 - val_loss: 0.8475 - val_accuracy: 0.8390\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/36 [==============================] - 4s 95ms/step - loss: 0.1862 - accuracy: 0.9363 - val_loss: 0.7465 - val_accuracy: 0.8256\n",
      "Epoch 117/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.1922 - accuracy: 0.9391 - val_loss: 0.7171 - val_accuracy: 0.8402\n",
      "Epoch 118/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.1506 - accuracy: 0.9482 - val_loss: 0.7993 - val_accuracy: 0.8421\n",
      "Epoch 119/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.1644 - accuracy: 0.9461 - val_loss: 0.8022 - val_accuracy: 0.8320\n",
      "Epoch 120/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.1728 - accuracy: 0.9450 - val_loss: 0.8194 - val_accuracy: 0.8383\n",
      "Epoch 121/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.1661 - accuracy: 0.9442 - val_loss: 0.7646 - val_accuracy: 0.8402\n",
      "Epoch 122/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.1646 - accuracy: 0.9433 - val_loss: 0.7794 - val_accuracy: 0.8440\n",
      "Epoch 123/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.1590 - accuracy: 0.9423 - val_loss: 0.7976 - val_accuracy: 0.8345\n",
      "Epoch 124/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.1736 - accuracy: 0.9476 - val_loss: 0.7040 - val_accuracy: 0.8364\n",
      "Epoch 125/500\n",
      "37/36 [==============================] - 4s 99ms/step - loss: 0.1744 - accuracy: 0.9442 - val_loss: 0.7664 - val_accuracy: 0.8383\n",
      "Epoch 126/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.1579 - accuracy: 0.9427 - val_loss: 0.7837 - val_accuracy: 0.8479\n",
      "Epoch 127/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.1550 - accuracy: 0.9482 - val_loss: 0.8004 - val_accuracy: 0.8402\n",
      "Epoch 128/500\n",
      "37/36 [==============================] - 4s 101ms/step - loss: 0.1485 - accuracy: 0.9533 - val_loss: 0.7934 - val_accuracy: 0.8345\n",
      "Epoch 129/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.1565 - accuracy: 0.9450 - val_loss: 0.7793 - val_accuracy: 0.8466\n",
      "Epoch 130/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.1481 - accuracy: 0.9516 - val_loss: 0.7386 - val_accuracy: 0.8415\n",
      "Epoch 131/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.1641 - accuracy: 0.9450 - val_loss: 0.7637 - val_accuracy: 0.8358\n",
      "Epoch 132/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.1529 - accuracy: 0.9499 - val_loss: 0.7372 - val_accuracy: 0.8440\n",
      "Epoch 133/500\n",
      "37/36 [==============================] - 3s 81ms/step - loss: 0.1509 - accuracy: 0.9501 - val_loss: 0.7600 - val_accuracy: 0.8428\n",
      "Epoch 134/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.1321 - accuracy: 0.9512 - val_loss: 0.8003 - val_accuracy: 0.8364\n",
      "Epoch 135/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.1471 - accuracy: 0.9493 - val_loss: 0.8030 - val_accuracy: 0.8269\n",
      "Epoch 136/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.1342 - accuracy: 0.9550 - val_loss: 0.8424 - val_accuracy: 0.8383\n",
      "Epoch 137/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.1308 - accuracy: 0.9508 - val_loss: 0.8808 - val_accuracy: 0.8383\n",
      "Epoch 138/500\n",
      "37/36 [==============================] - 4s 107ms/step - loss: 0.1436 - accuracy: 0.9518 - val_loss: 0.8669 - val_accuracy: 0.8326\n",
      "Epoch 139/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.1379 - accuracy: 0.9514 - val_loss: 0.8713 - val_accuracy: 0.8383\n",
      "Epoch 140/500\n",
      "37/36 [==============================] - 3s 81ms/step - loss: 0.1617 - accuracy: 0.9444 - val_loss: 0.7440 - val_accuracy: 0.8421\n",
      "Epoch 141/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.1353 - accuracy: 0.9522 - val_loss: 0.8290 - val_accuracy: 0.8447\n",
      "Epoch 142/500\n",
      "37/36 [==============================] - 4s 96ms/step - loss: 0.1501 - accuracy: 0.9486 - val_loss: 0.7825 - val_accuracy: 0.8434\n",
      "Epoch 143/500\n",
      "37/36 [==============================] - 4s 98ms/step - loss: 0.1308 - accuracy: 0.9571 - val_loss: 0.8062 - val_accuracy: 0.8472\n",
      "Epoch 144/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.1471 - accuracy: 0.9539 - val_loss: 0.8051 - val_accuracy: 0.8332\n",
      "Epoch 145/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.1226 - accuracy: 0.9563 - val_loss: 0.8415 - val_accuracy: 0.8421\n",
      "Epoch 146/500\n",
      "37/36 [==============================] - 3s 81ms/step - loss: 0.1442 - accuracy: 0.9499 - val_loss: 0.7793 - val_accuracy: 0.8447\n",
      "Epoch 147/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.1263 - accuracy: 0.9548 - val_loss: 0.7733 - val_accuracy: 0.8415\n",
      "Epoch 148/500\n",
      "37/36 [==============================] - 4s 103ms/step - loss: 0.1290 - accuracy: 0.9556 - val_loss: 0.8536 - val_accuracy: 0.8479\n",
      "Epoch 149/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.1432 - accuracy: 0.9527 - val_loss: 0.7966 - val_accuracy: 0.8396\n",
      "Epoch 150/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.1256 - accuracy: 0.9556 - val_loss: 0.8163 - val_accuracy: 0.8453\n",
      "Epoch 151/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.1354 - accuracy: 0.9544 - val_loss: 0.8290 - val_accuracy: 0.8409\n",
      "Epoch 152/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.1255 - accuracy: 0.9552 - val_loss: 0.8567 - val_accuracy: 0.8440\n",
      "Epoch 153/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.1325 - accuracy: 0.9552 - val_loss: 0.7924 - val_accuracy: 0.8466\n",
      "Epoch 154/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.1371 - accuracy: 0.9563 - val_loss: 0.8206 - val_accuracy: 0.8383\n",
      "Epoch 155/500\n",
      "37/36 [==============================] - 4s 102ms/step - loss: 0.1197 - accuracy: 0.9631 - val_loss: 0.8187 - val_accuracy: 0.8428\n",
      "Epoch 156/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.1111 - accuracy: 0.9605 - val_loss: 0.8769 - val_accuracy: 0.8466\n",
      "Epoch 157/500\n",
      "37/36 [==============================] - 4s 97ms/step - loss: 0.1271 - accuracy: 0.9556 - val_loss: 0.8324 - val_accuracy: 0.8409\n",
      "Epoch 158/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.1237 - accuracy: 0.9571 - val_loss: 0.8651 - val_accuracy: 0.8466\n",
      "Epoch 159/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.1173 - accuracy: 0.9622 - val_loss: 0.8012 - val_accuracy: 0.8332\n",
      "Epoch 160/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.1284 - accuracy: 0.9556 - val_loss: 0.8696 - val_accuracy: 0.8434\n",
      "Epoch 161/500\n",
      "37/36 [==============================] - 4s 97ms/step - loss: 0.1248 - accuracy: 0.9567 - val_loss: 0.8633 - val_accuracy: 0.8377\n",
      "Epoch 162/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.1142 - accuracy: 0.9610 - val_loss: 0.8113 - val_accuracy: 0.8390\n",
      "Epoch 163/500\n",
      "37/36 [==============================] - 4s 97ms/step - loss: 0.1171 - accuracy: 0.9612 - val_loss: 0.8913 - val_accuracy: 0.8313\n",
      "Epoch 164/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.1118 - accuracy: 0.9610 - val_loss: 0.8635 - val_accuracy: 0.8440\n",
      "Epoch 165/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.1278 - accuracy: 0.9603 - val_loss: 0.8087 - val_accuracy: 0.8409\n",
      "Epoch 166/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.1246 - accuracy: 0.9588 - val_loss: 0.8235 - val_accuracy: 0.8205\n",
      "Epoch 167/500\n",
      "37/36 [==============================] - 4s 96ms/step - loss: 0.1262 - accuracy: 0.9582 - val_loss: 0.8546 - val_accuracy: 0.8434\n",
      "Epoch 168/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.1222 - accuracy: 0.9567 - val_loss: 0.8466 - val_accuracy: 0.8511\n",
      "Epoch 169/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.1072 - accuracy: 0.9631 - val_loss: 0.8583 - val_accuracy: 0.8434\n",
      "Epoch 170/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.1075 - accuracy: 0.9603 - val_loss: 0.9278 - val_accuracy: 0.8434\n",
      "Epoch 171/500\n",
      "37/36 [==============================] - 4s 98ms/step - loss: 0.1229 - accuracy: 0.9605 - val_loss: 0.8862 - val_accuracy: 0.8351\n",
      "Epoch 172/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.1144 - accuracy: 0.9629 - val_loss: 0.9152 - val_accuracy: 0.8370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.1246 - accuracy: 0.9584 - val_loss: 0.7888 - val_accuracy: 0.8402\n",
      "Epoch 174/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.1124 - accuracy: 0.9626 - val_loss: 0.8150 - val_accuracy: 0.8364\n",
      "Epoch 175/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.1235 - accuracy: 0.9586 - val_loss: 0.8694 - val_accuracy: 0.8358\n",
      "Epoch 176/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.1203 - accuracy: 0.9576 - val_loss: 0.9246 - val_accuracy: 0.8390\n",
      "Epoch 177/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.1168 - accuracy: 0.9622 - val_loss: 0.8504 - val_accuracy: 0.8332\n",
      "Epoch 178/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.1273 - accuracy: 0.9603 - val_loss: 0.8518 - val_accuracy: 0.8345\n",
      "Epoch 179/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.1091 - accuracy: 0.9650 - val_loss: 0.8632 - val_accuracy: 0.8466\n",
      "Epoch 180/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.1148 - accuracy: 0.9643 - val_loss: 0.8850 - val_accuracy: 0.8307\n",
      "Epoch 181/500\n",
      "37/36 [==============================] - 4s 99ms/step - loss: 0.1067 - accuracy: 0.9622 - val_loss: 0.8761 - val_accuracy: 0.8390\n",
      "Epoch 182/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.1056 - accuracy: 0.9652 - val_loss: 0.9009 - val_accuracy: 0.8460\n",
      "Epoch 183/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.1086 - accuracy: 0.9641 - val_loss: 0.8865 - val_accuracy: 0.8377\n",
      "Epoch 184/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.1110 - accuracy: 0.9605 - val_loss: 0.9493 - val_accuracy: 0.8345\n",
      "Epoch 185/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.1059 - accuracy: 0.9643 - val_loss: 0.8755 - val_accuracy: 0.8370\n",
      "Epoch 186/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.1015 - accuracy: 0.9665 - val_loss: 0.9069 - val_accuracy: 0.8440\n",
      "Epoch 187/500\n",
      "37/36 [==============================] - 3s 94ms/step - loss: 0.1030 - accuracy: 0.9629 - val_loss: 0.9094 - val_accuracy: 0.8300\n",
      "Epoch 188/500\n",
      "37/36 [==============================] - 3s 94ms/step - loss: 0.1003 - accuracy: 0.9673 - val_loss: 0.9478 - val_accuracy: 0.8440\n",
      "Epoch 189/500\n",
      "37/36 [==============================] - 4s 96ms/step - loss: 0.1083 - accuracy: 0.9663 - val_loss: 0.8485 - val_accuracy: 0.8402\n",
      "Epoch 190/500\n",
      "37/36 [==============================] - 4s 95ms/step - loss: 0.0907 - accuracy: 0.9703 - val_loss: 0.8874 - val_accuracy: 0.8377\n",
      "Epoch 191/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.0951 - accuracy: 0.9680 - val_loss: 0.9204 - val_accuracy: 0.8421\n",
      "Epoch 192/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.1012 - accuracy: 0.9646 - val_loss: 0.8822 - val_accuracy: 0.8370\n",
      "Epoch 193/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.1077 - accuracy: 0.9616 - val_loss: 0.9249 - val_accuracy: 0.8402\n",
      "Epoch 194/500\n",
      "37/36 [==============================] - 3s 94ms/step - loss: 0.1218 - accuracy: 0.9631 - val_loss: 0.8961 - val_accuracy: 0.8396\n",
      "Epoch 195/500\n",
      "37/36 [==============================] - 4s 102ms/step - loss: 0.0951 - accuracy: 0.9667 - val_loss: 0.9118 - val_accuracy: 0.8390\n",
      "Epoch 196/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0970 - accuracy: 0.9671 - val_loss: 0.8169 - val_accuracy: 0.8453\n",
      "Epoch 197/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.1023 - accuracy: 0.9656 - val_loss: 0.9091 - val_accuracy: 0.8390\n",
      "Epoch 198/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.1062 - accuracy: 0.9652 - val_loss: 0.8964 - val_accuracy: 0.8358\n",
      "Epoch 199/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.1039 - accuracy: 0.9686 - val_loss: 0.8814 - val_accuracy: 0.8453\n",
      "Epoch 200/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.0998 - accuracy: 0.9654 - val_loss: 0.9038 - val_accuracy: 0.8402\n",
      "Epoch 201/500\n",
      "37/36 [==============================] - 4s 95ms/step - loss: 0.1061 - accuracy: 0.9677 - val_loss: 0.9062 - val_accuracy: 0.8555\n",
      "Epoch 202/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.1001 - accuracy: 0.9663 - val_loss: 0.8538 - val_accuracy: 0.8415\n",
      "Epoch 203/500\n",
      "37/36 [==============================] - 4s 97ms/step - loss: 0.0936 - accuracy: 0.9682 - val_loss: 0.8483 - val_accuracy: 0.8491\n",
      "Epoch 204/500\n",
      "37/36 [==============================] - 3s 80ms/step - loss: 0.0913 - accuracy: 0.9680 - val_loss: 0.8953 - val_accuracy: 0.8542\n",
      "Epoch 205/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.0992 - accuracy: 0.9682 - val_loss: 0.8316 - val_accuracy: 0.8466\n",
      "Epoch 206/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0963 - accuracy: 0.9682 - val_loss: 1.0283 - val_accuracy: 0.8358\n",
      "Epoch 207/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.0936 - accuracy: 0.9694 - val_loss: 0.9491 - val_accuracy: 0.8320\n",
      "Epoch 208/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.1090 - accuracy: 0.9652 - val_loss: 0.8583 - val_accuracy: 0.8440\n",
      "Epoch 209/500\n",
      "37/36 [==============================] - 4s 97ms/step - loss: 0.0867 - accuracy: 0.9713 - val_loss: 0.8897 - val_accuracy: 0.8415\n",
      "Epoch 210/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0998 - accuracy: 0.9671 - val_loss: 0.8350 - val_accuracy: 0.8364\n",
      "Epoch 211/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0860 - accuracy: 0.9684 - val_loss: 0.9195 - val_accuracy: 0.8294\n",
      "Epoch 212/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0928 - accuracy: 0.9682 - val_loss: 0.9769 - val_accuracy: 0.8428\n",
      "Epoch 213/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0955 - accuracy: 0.9677 - val_loss: 0.8759 - val_accuracy: 0.8428\n",
      "Epoch 214/500\n",
      "37/36 [==============================] - 4s 98ms/step - loss: 0.0876 - accuracy: 0.9730 - val_loss: 0.8887 - val_accuracy: 0.8453\n",
      "Epoch 215/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0968 - accuracy: 0.9671 - val_loss: 0.9570 - val_accuracy: 0.8568\n",
      "Epoch 216/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0981 - accuracy: 0.9667 - val_loss: 0.9461 - val_accuracy: 0.8479\n",
      "Epoch 217/500\n",
      "37/36 [==============================] - 3s 80ms/step - loss: 0.0821 - accuracy: 0.9722 - val_loss: 0.9061 - val_accuracy: 0.8415\n",
      "Epoch 218/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0833 - accuracy: 0.9703 - val_loss: 0.8949 - val_accuracy: 0.8472\n",
      "Epoch 219/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.0973 - accuracy: 0.9658 - val_loss: 0.8552 - val_accuracy: 0.8453\n",
      "Epoch 220/500\n",
      "37/36 [==============================] - 4s 95ms/step - loss: 0.0897 - accuracy: 0.9709 - val_loss: 0.9302 - val_accuracy: 0.8377\n",
      "Epoch 221/500\n",
      "37/36 [==============================] - 4s 95ms/step - loss: 0.0876 - accuracy: 0.9684 - val_loss: 0.8969 - val_accuracy: 0.8415\n",
      "Epoch 222/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.0827 - accuracy: 0.9707 - val_loss: 0.9811 - val_accuracy: 0.8409\n",
      "Epoch 223/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.1011 - accuracy: 0.9650 - val_loss: 0.9652 - val_accuracy: 0.8339\n",
      "Epoch 224/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0917 - accuracy: 0.9680 - val_loss: 1.0135 - val_accuracy: 0.8294\n",
      "Epoch 225/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.0926 - accuracy: 0.9680 - val_loss: 0.9648 - val_accuracy: 0.8332\n",
      "Epoch 226/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0904 - accuracy: 0.9747 - val_loss: 1.0038 - val_accuracy: 0.8351\n",
      "Epoch 227/500\n",
      "37/36 [==============================] - 4s 107ms/step - loss: 0.0891 - accuracy: 0.9703 - val_loss: 0.9414 - val_accuracy: 0.8377\n",
      "Epoch 228/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.0804 - accuracy: 0.9724 - val_loss: 1.0175 - val_accuracy: 0.8370\n",
      "Epoch 229/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0850 - accuracy: 0.9703 - val_loss: 0.9525 - val_accuracy: 0.8377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/500\n",
      "37/36 [==============================] - 3s 79ms/step - loss: 0.0874 - accuracy: 0.9701 - val_loss: 1.0230 - val_accuracy: 0.8447\n",
      "Epoch 231/500\n",
      "37/36 [==============================] - 3s 78ms/step - loss: 0.0806 - accuracy: 0.9720 - val_loss: 0.9798 - val_accuracy: 0.8358\n",
      "Epoch 232/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0860 - accuracy: 0.9711 - val_loss: 0.8911 - val_accuracy: 0.8370\n",
      "Epoch 233/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.0871 - accuracy: 0.9730 - val_loss: 0.9735 - val_accuracy: 0.8409\n",
      "Epoch 234/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0806 - accuracy: 0.9705 - val_loss: 0.9937 - val_accuracy: 0.8460\n",
      "Epoch 235/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.1010 - accuracy: 0.9658 - val_loss: 0.9276 - val_accuracy: 0.8434\n",
      "Epoch 236/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0844 - accuracy: 0.9694 - val_loss: 0.9630 - val_accuracy: 0.8453\n",
      "Epoch 237/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.0867 - accuracy: 0.9707 - val_loss: 1.0064 - val_accuracy: 0.8396\n",
      "Epoch 238/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0802 - accuracy: 0.9754 - val_loss: 1.0338 - val_accuracy: 0.8390\n",
      "Epoch 239/500\n",
      "37/36 [==============================] - 3s 94ms/step - loss: 0.0824 - accuracy: 0.9713 - val_loss: 0.9777 - val_accuracy: 0.8440\n",
      "Epoch 240/500\n",
      "37/36 [==============================] - 4s 95ms/step - loss: 0.0829 - accuracy: 0.9724 - val_loss: 1.0656 - val_accuracy: 0.8466\n",
      "Epoch 241/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0896 - accuracy: 0.9692 - val_loss: 1.0384 - val_accuracy: 0.8345\n",
      "Epoch 242/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0862 - accuracy: 0.9707 - val_loss: 1.0718 - val_accuracy: 0.8307\n",
      "Epoch 243/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0784 - accuracy: 0.9728 - val_loss: 0.9677 - val_accuracy: 0.8415\n",
      "Epoch 244/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.0946 - accuracy: 0.9671 - val_loss: 0.9614 - val_accuracy: 0.8370\n",
      "Epoch 245/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0872 - accuracy: 0.9730 - val_loss: 1.0176 - val_accuracy: 0.8402\n",
      "Epoch 246/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.0793 - accuracy: 0.9733 - val_loss: 1.0183 - val_accuracy: 0.8504\n",
      "Epoch 247/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.0772 - accuracy: 0.9735 - val_loss: 0.9724 - val_accuracy: 0.8396\n",
      "Epoch 248/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0767 - accuracy: 0.9762 - val_loss: 1.0130 - val_accuracy: 0.8383\n",
      "Epoch 249/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0849 - accuracy: 0.9722 - val_loss: 0.9828 - val_accuracy: 0.8479\n",
      "Epoch 250/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0828 - accuracy: 0.9741 - val_loss: 1.0180 - val_accuracy: 0.8396\n",
      "Epoch 251/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0919 - accuracy: 0.9682 - val_loss: 0.9736 - val_accuracy: 0.8409\n",
      "Epoch 252/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.0803 - accuracy: 0.9771 - val_loss: 0.9624 - val_accuracy: 0.8370\n",
      "Epoch 253/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0686 - accuracy: 0.9773 - val_loss: 1.0174 - val_accuracy: 0.8453\n",
      "Epoch 254/500\n",
      "37/36 [==============================] - 4s 106ms/step - loss: 0.0717 - accuracy: 0.9750 - val_loss: 1.0523 - val_accuracy: 0.8377\n",
      "Epoch 255/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.0754 - accuracy: 0.9764 - val_loss: 1.0328 - val_accuracy: 0.8447\n",
      "Epoch 256/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.0802 - accuracy: 0.9737 - val_loss: 0.9628 - val_accuracy: 0.8479\n",
      "Epoch 257/500\n",
      "37/36 [==============================] - 4s 99ms/step - loss: 0.0714 - accuracy: 0.9767 - val_loss: 1.0233 - val_accuracy: 0.8453\n",
      "Epoch 258/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0723 - accuracy: 0.9767 - val_loss: 1.0320 - val_accuracy: 0.8377\n",
      "Epoch 259/500\n",
      "37/36 [==============================] - 3s 80ms/step - loss: 0.0728 - accuracy: 0.9781 - val_loss: 1.0553 - val_accuracy: 0.8440\n",
      "Epoch 260/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.0726 - accuracy: 0.9760 - val_loss: 0.9838 - val_accuracy: 0.8428\n",
      "Epoch 261/500\n",
      "37/36 [==============================] - 3s 94ms/step - loss: 0.0736 - accuracy: 0.9779 - val_loss: 0.9189 - val_accuracy: 0.8370\n",
      "Epoch 262/500\n",
      "37/36 [==============================] - 3s 80ms/step - loss: 0.0822 - accuracy: 0.9735 - val_loss: 0.9585 - val_accuracy: 0.8370\n",
      "Epoch 263/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0790 - accuracy: 0.9726 - val_loss: 1.0069 - val_accuracy: 0.8485\n",
      "Epoch 264/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.0706 - accuracy: 0.9796 - val_loss: 1.0565 - val_accuracy: 0.8440\n",
      "Epoch 265/500\n",
      "37/36 [==============================] - 3s 77ms/step - loss: 0.0637 - accuracy: 0.9794 - val_loss: 1.0676 - val_accuracy: 0.8313\n",
      "Epoch 266/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.0677 - accuracy: 0.9747 - val_loss: 1.0640 - val_accuracy: 0.8421\n",
      "Epoch 267/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.0731 - accuracy: 0.9775 - val_loss: 1.0232 - val_accuracy: 0.8377\n",
      "Epoch 268/500\n",
      "37/36 [==============================] - 4s 100ms/step - loss: 0.0707 - accuracy: 0.9760 - val_loss: 1.0249 - val_accuracy: 0.8415\n",
      "Epoch 269/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0697 - accuracy: 0.9790 - val_loss: 1.0045 - val_accuracy: 0.8313\n",
      "Epoch 270/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0669 - accuracy: 0.9756 - val_loss: 1.0863 - val_accuracy: 0.8421\n",
      "Epoch 271/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0805 - accuracy: 0.9743 - val_loss: 0.9702 - val_accuracy: 0.8390\n",
      "Epoch 272/500\n",
      "37/36 [==============================] - 3s 80ms/step - loss: 0.0704 - accuracy: 0.9754 - val_loss: 1.0129 - val_accuracy: 0.8536\n",
      "Epoch 273/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.0657 - accuracy: 0.9805 - val_loss: 0.9861 - val_accuracy: 0.8542\n",
      "Epoch 274/500\n",
      "37/36 [==============================] - 4s 98ms/step - loss: 0.0661 - accuracy: 0.9813 - val_loss: 0.9846 - val_accuracy: 0.8504\n",
      "Epoch 275/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0907 - accuracy: 0.9705 - val_loss: 0.9618 - val_accuracy: 0.8555\n",
      "Epoch 276/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0688 - accuracy: 0.9767 - val_loss: 1.0266 - val_accuracy: 0.8428\n",
      "Epoch 277/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.0566 - accuracy: 0.9788 - val_loss: 1.0892 - val_accuracy: 0.8466\n",
      "Epoch 278/500\n",
      "37/36 [==============================] - 3s 77ms/step - loss: 0.0816 - accuracy: 0.9735 - val_loss: 0.9361 - val_accuracy: 0.8485\n",
      "Epoch 279/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0793 - accuracy: 0.9745 - val_loss: 0.9952 - val_accuracy: 0.8504\n",
      "Epoch 280/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0720 - accuracy: 0.9752 - val_loss: 0.9990 - val_accuracy: 0.8561\n",
      "Epoch 281/500\n",
      "37/36 [==============================] - 4s 97ms/step - loss: 0.0755 - accuracy: 0.9741 - val_loss: 0.9830 - val_accuracy: 0.8428\n",
      "Epoch 282/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0620 - accuracy: 0.9779 - val_loss: 1.0416 - val_accuracy: 0.8498\n",
      "Epoch 283/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0788 - accuracy: 0.9760 - val_loss: 1.0165 - val_accuracy: 0.8453\n",
      "Epoch 284/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0850 - accuracy: 0.9728 - val_loss: 0.9456 - val_accuracy: 0.8479\n",
      "Epoch 285/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0793 - accuracy: 0.9730 - val_loss: 0.9580 - val_accuracy: 0.8428\n",
      "Epoch 286/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0727 - accuracy: 0.9762 - val_loss: 0.9705 - val_accuracy: 0.8421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0713 - accuracy: 0.9760 - val_loss: 0.9346 - val_accuracy: 0.8440\n",
      "Epoch 288/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.0616 - accuracy: 0.9792 - val_loss: 0.9811 - val_accuracy: 0.8472\n",
      "Epoch 289/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0703 - accuracy: 0.9773 - val_loss: 1.0213 - val_accuracy: 0.8479\n",
      "Epoch 290/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0691 - accuracy: 0.9777 - val_loss: 1.0001 - val_accuracy: 0.8511\n",
      "Epoch 291/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0582 - accuracy: 0.9803 - val_loss: 1.0161 - val_accuracy: 0.8523\n",
      "Epoch 292/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0517 - accuracy: 0.9809 - val_loss: 1.1357 - val_accuracy: 0.8491\n",
      "Epoch 293/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0643 - accuracy: 0.9798 - val_loss: 1.0797 - val_accuracy: 0.8466\n",
      "Epoch 294/500\n",
      "37/36 [==============================] - 4s 102ms/step - loss: 0.0666 - accuracy: 0.9807 - val_loss: 1.0366 - val_accuracy: 0.8447\n",
      "Epoch 295/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.0737 - accuracy: 0.9758 - val_loss: 1.0207 - val_accuracy: 0.8485\n",
      "Epoch 296/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0579 - accuracy: 0.9824 - val_loss: 1.1040 - val_accuracy: 0.8428\n",
      "Epoch 297/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0626 - accuracy: 0.9788 - val_loss: 1.0593 - val_accuracy: 0.8536\n",
      "Epoch 298/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0576 - accuracy: 0.9811 - val_loss: 1.0737 - val_accuracy: 0.8472\n",
      "Epoch 299/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0827 - accuracy: 0.9739 - val_loss: 1.0439 - val_accuracy: 0.8453\n",
      "Epoch 300/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.0630 - accuracy: 0.9781 - val_loss: 0.9929 - val_accuracy: 0.8498\n",
      "Epoch 301/500\n",
      "37/36 [==============================] - 4s 104ms/step - loss: 0.0686 - accuracy: 0.9790 - val_loss: 0.9587 - val_accuracy: 0.8511\n",
      "Epoch 302/500\n",
      "37/36 [==============================] - 4s 96ms/step - loss: 0.0641 - accuracy: 0.9788 - val_loss: 0.9868 - val_accuracy: 0.8498\n",
      "Epoch 303/500\n",
      "37/36 [==============================] - 4s 98ms/step - loss: 0.0568 - accuracy: 0.9813 - val_loss: 1.1036 - val_accuracy: 0.8472\n",
      "Epoch 304/500\n",
      "37/36 [==============================] - 3s 80ms/step - loss: 0.0695 - accuracy: 0.9798 - val_loss: 1.0601 - val_accuracy: 0.8549\n",
      "Epoch 305/500\n",
      "37/36 [==============================] - 3s 80ms/step - loss: 0.0706 - accuracy: 0.9796 - val_loss: 0.9857 - val_accuracy: 0.8523\n",
      "Epoch 306/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0601 - accuracy: 0.9822 - val_loss: 0.9776 - val_accuracy: 0.8472\n",
      "Epoch 307/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0546 - accuracy: 0.9815 - val_loss: 1.0207 - val_accuracy: 0.8542\n",
      "Epoch 308/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.0713 - accuracy: 0.9773 - val_loss: 0.9817 - val_accuracy: 0.8511\n",
      "Epoch 309/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0670 - accuracy: 0.9794 - val_loss: 0.9820 - val_accuracy: 0.8472\n",
      "Epoch 310/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.0615 - accuracy: 0.9801 - val_loss: 1.0328 - val_accuracy: 0.8593\n",
      "Epoch 311/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0547 - accuracy: 0.9824 - val_loss: 0.9797 - val_accuracy: 0.8561\n",
      "Epoch 312/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0671 - accuracy: 0.9758 - val_loss: 1.0117 - val_accuracy: 0.8517\n",
      "Epoch 313/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0604 - accuracy: 0.9792 - val_loss: 1.1042 - val_accuracy: 0.8504\n",
      "Epoch 314/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.0616 - accuracy: 0.9775 - val_loss: 1.0097 - val_accuracy: 0.8479\n",
      "Epoch 315/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.0600 - accuracy: 0.9809 - val_loss: 1.0087 - val_accuracy: 0.8542\n",
      "Epoch 316/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0576 - accuracy: 0.9824 - val_loss: 1.0624 - val_accuracy: 0.8555\n",
      "Epoch 317/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0542 - accuracy: 0.9824 - val_loss: 1.0613 - val_accuracy: 0.8472\n",
      "Epoch 318/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0693 - accuracy: 0.9779 - val_loss: 1.0031 - val_accuracy: 0.8530\n",
      "Epoch 319/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0710 - accuracy: 0.9777 - val_loss: 0.9532 - val_accuracy: 0.8568\n",
      "Epoch 320/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.0644 - accuracy: 0.9777 - val_loss: 1.0067 - val_accuracy: 0.8498\n",
      "Epoch 321/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.0656 - accuracy: 0.9790 - val_loss: 1.0016 - val_accuracy: 0.8498\n",
      "Epoch 322/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.0704 - accuracy: 0.9786 - val_loss: 0.9549 - val_accuracy: 0.8568\n",
      "Epoch 323/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0614 - accuracy: 0.9807 - val_loss: 1.1154 - val_accuracy: 0.8517\n",
      "Epoch 324/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0682 - accuracy: 0.9784 - val_loss: 1.0740 - val_accuracy: 0.8511\n",
      "Epoch 325/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0689 - accuracy: 0.9773 - val_loss: 1.0769 - val_accuracy: 0.8460\n",
      "Epoch 326/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.0599 - accuracy: 0.9786 - val_loss: 0.9957 - val_accuracy: 0.8530\n",
      "Epoch 327/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0582 - accuracy: 0.9798 - val_loss: 1.0558 - val_accuracy: 0.8498\n",
      "Epoch 328/500\n",
      "37/36 [==============================] - 4s 103ms/step - loss: 0.0733 - accuracy: 0.9762 - val_loss: 1.0169 - val_accuracy: 0.8479\n",
      "Epoch 329/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.0655 - accuracy: 0.9781 - val_loss: 1.0007 - val_accuracy: 0.8517\n",
      "Epoch 330/500\n",
      "37/36 [==============================] - 3s 81ms/step - loss: 0.0654 - accuracy: 0.9779 - val_loss: 1.0305 - val_accuracy: 0.8472\n",
      "Epoch 331/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0654 - accuracy: 0.9796 - val_loss: 1.0223 - val_accuracy: 0.8485\n",
      "Epoch 332/500\n",
      "37/36 [==============================] - 3s 78ms/step - loss: 0.0625 - accuracy: 0.9773 - val_loss: 1.0096 - val_accuracy: 0.8447\n",
      "Epoch 333/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.0534 - accuracy: 0.9839 - val_loss: 1.0140 - val_accuracy: 0.8479\n",
      "Epoch 334/500\n",
      "37/36 [==============================] - 4s 98ms/step - loss: 0.0541 - accuracy: 0.9817 - val_loss: 0.9707 - val_accuracy: 0.8504\n",
      "Epoch 335/500\n",
      "37/36 [==============================] - 3s 94ms/step - loss: 0.0581 - accuracy: 0.9796 - val_loss: 1.0751 - val_accuracy: 0.8409\n",
      "Epoch 336/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0652 - accuracy: 0.9798 - val_loss: 0.9855 - val_accuracy: 0.8402\n",
      "Epoch 337/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0503 - accuracy: 0.9830 - val_loss: 1.0591 - val_accuracy: 0.8517\n",
      "Epoch 338/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0616 - accuracy: 0.9811 - val_loss: 1.0518 - val_accuracy: 0.8485\n",
      "Epoch 339/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0603 - accuracy: 0.9807 - val_loss: 1.0232 - val_accuracy: 0.8530\n",
      "Epoch 340/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0568 - accuracy: 0.9817 - val_loss: 1.0372 - val_accuracy: 0.8498\n",
      "Epoch 341/500\n",
      "37/36 [==============================] - 4s 97ms/step - loss: 0.0546 - accuracy: 0.9815 - val_loss: 1.0948 - val_accuracy: 0.8485\n",
      "Epoch 342/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0499 - accuracy: 0.9828 - val_loss: 1.0933 - val_accuracy: 0.8555\n",
      "Epoch 343/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0653 - accuracy: 0.9779 - val_loss: 1.0222 - val_accuracy: 0.8453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/500\n",
      "37/36 [==============================] - 3s 80ms/step - loss: 0.0661 - accuracy: 0.9798 - val_loss: 0.9740 - val_accuracy: 0.8453\n",
      "Epoch 345/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0586 - accuracy: 0.9803 - val_loss: 1.0612 - val_accuracy: 0.8517\n",
      "Epoch 346/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0437 - accuracy: 0.9843 - val_loss: 1.1218 - val_accuracy: 0.8466\n",
      "Epoch 347/500\n",
      "37/36 [==============================] - 4s 96ms/step - loss: 0.0489 - accuracy: 0.9839 - val_loss: 1.0961 - val_accuracy: 0.8485\n",
      "Epoch 348/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0508 - accuracy: 0.9832 - val_loss: 1.1146 - val_accuracy: 0.8498\n",
      "Epoch 349/500\n",
      "37/36 [==============================] - 4s 95ms/step - loss: 0.0579 - accuracy: 0.9845 - val_loss: 1.0831 - val_accuracy: 0.8453\n",
      "Epoch 350/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0577 - accuracy: 0.9811 - val_loss: 1.0888 - val_accuracy: 0.8453\n",
      "Epoch 351/500\n",
      "37/36 [==============================] - 4s 95ms/step - loss: 0.0664 - accuracy: 0.9794 - val_loss: 1.1417 - val_accuracy: 0.8326\n",
      "Epoch 352/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0526 - accuracy: 0.9820 - val_loss: 1.0852 - val_accuracy: 0.8453\n",
      "Epoch 353/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0582 - accuracy: 0.9807 - val_loss: 1.0260 - val_accuracy: 0.8574\n",
      "Epoch 354/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.0547 - accuracy: 0.9815 - val_loss: 1.0487 - val_accuracy: 0.8479\n",
      "Epoch 355/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.0606 - accuracy: 0.9801 - val_loss: 1.0329 - val_accuracy: 0.8390\n",
      "Epoch 356/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0545 - accuracy: 0.9817 - val_loss: 1.0900 - val_accuracy: 0.8332\n",
      "Epoch 357/500\n",
      "37/36 [==============================] - 3s 80ms/step - loss: 0.0657 - accuracy: 0.9792 - val_loss: 1.0172 - val_accuracy: 0.8498\n",
      "Epoch 358/500\n",
      "37/36 [==============================] - 3s 80ms/step - loss: 0.0663 - accuracy: 0.9777 - val_loss: 1.0599 - val_accuracy: 0.8549\n",
      "Epoch 359/500\n",
      "37/36 [==============================] - 3s 94ms/step - loss: 0.0613 - accuracy: 0.9801 - val_loss: 1.0245 - val_accuracy: 0.8536\n",
      "Epoch 360/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0510 - accuracy: 0.9822 - val_loss: 1.0151 - val_accuracy: 0.8517\n",
      "Epoch 361/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.0553 - accuracy: 0.9839 - val_loss: 0.9882 - val_accuracy: 0.8517\n",
      "Epoch 362/500\n",
      "37/36 [==============================] - 4s 101ms/step - loss: 0.0607 - accuracy: 0.9794 - val_loss: 1.0002 - val_accuracy: 0.8428\n",
      "Epoch 363/500\n",
      "37/36 [==============================] - 4s 99ms/step - loss: 0.0548 - accuracy: 0.9834 - val_loss: 1.0709 - val_accuracy: 0.8453\n",
      "Epoch 364/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0469 - accuracy: 0.9851 - val_loss: 1.1284 - val_accuracy: 0.8472\n",
      "Epoch 365/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0658 - accuracy: 0.9798 - val_loss: 1.0824 - val_accuracy: 0.8370\n",
      "Epoch 366/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0556 - accuracy: 0.9815 - val_loss: 1.0800 - val_accuracy: 0.8511\n",
      "Epoch 367/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.0713 - accuracy: 0.9771 - val_loss: 1.0423 - val_accuracy: 0.8561\n",
      "Epoch 368/500\n",
      "37/36 [==============================] - 4s 96ms/step - loss: 0.0571 - accuracy: 0.9803 - val_loss: 1.0346 - val_accuracy: 0.8472\n",
      "Epoch 369/500\n",
      "37/36 [==============================] - 4s 95ms/step - loss: 0.0446 - accuracy: 0.9834 - val_loss: 1.1402 - val_accuracy: 0.8511\n",
      "Epoch 370/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0595 - accuracy: 0.9830 - val_loss: 1.0655 - val_accuracy: 0.8517\n",
      "Epoch 371/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0540 - accuracy: 0.9826 - val_loss: 1.1620 - val_accuracy: 0.8415\n",
      "Epoch 372/500\n",
      "37/36 [==============================] - 3s 81ms/step - loss: 0.0635 - accuracy: 0.9758 - val_loss: 1.0905 - val_accuracy: 0.8409\n",
      "Epoch 373/500\n",
      "37/36 [==============================] - 3s 80ms/step - loss: 0.0639 - accuracy: 0.9815 - val_loss: 0.9638 - val_accuracy: 0.8523\n",
      "Epoch 374/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0496 - accuracy: 0.9851 - val_loss: 0.9874 - val_accuracy: 0.8593\n",
      "Epoch 375/500\n",
      "37/36 [==============================] - 4s 102ms/step - loss: 0.0532 - accuracy: 0.9839 - val_loss: 1.0751 - val_accuracy: 0.8511\n",
      "Epoch 376/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0505 - accuracy: 0.9834 - val_loss: 1.0789 - val_accuracy: 0.8517\n",
      "Epoch 377/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.0588 - accuracy: 0.9824 - val_loss: 1.1335 - val_accuracy: 0.8511\n",
      "Epoch 378/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.0483 - accuracy: 0.9849 - val_loss: 1.1735 - val_accuracy: 0.8530\n",
      "Epoch 379/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0554 - accuracy: 0.9813 - val_loss: 1.0087 - val_accuracy: 0.8549\n",
      "Epoch 380/500\n",
      "37/36 [==============================] - 3s 81ms/step - loss: 0.0463 - accuracy: 0.9849 - val_loss: 1.1324 - val_accuracy: 0.8440\n",
      "Epoch 381/500\n",
      "37/36 [==============================] - 3s 94ms/step - loss: 0.0588 - accuracy: 0.9815 - val_loss: 1.1077 - val_accuracy: 0.8434\n",
      "Epoch 382/500\n",
      "37/36 [==============================] - 3s 81ms/step - loss: 0.0494 - accuracy: 0.9839 - val_loss: 1.1749 - val_accuracy: 0.8530\n",
      "Epoch 383/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0489 - accuracy: 0.9851 - val_loss: 1.1077 - val_accuracy: 0.8491\n",
      "Epoch 384/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.0501 - accuracy: 0.9830 - val_loss: 1.0710 - val_accuracy: 0.8383\n",
      "Epoch 385/500\n",
      "37/36 [==============================] - 3s 80ms/step - loss: 0.0645 - accuracy: 0.9807 - val_loss: 1.0534 - val_accuracy: 0.8460\n",
      "Epoch 386/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0652 - accuracy: 0.9792 - val_loss: 1.0219 - val_accuracy: 0.8555\n",
      "Epoch 387/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0410 - accuracy: 0.9864 - val_loss: 1.1440 - val_accuracy: 0.8440\n",
      "Epoch 388/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0505 - accuracy: 0.9837 - val_loss: 1.1776 - val_accuracy: 0.8479\n",
      "Epoch 389/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0554 - accuracy: 0.9837 - val_loss: 1.1552 - val_accuracy: 0.8428\n",
      "Epoch 390/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0484 - accuracy: 0.9854 - val_loss: 1.1125 - val_accuracy: 0.8453\n",
      "Epoch 391/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.0539 - accuracy: 0.9817 - val_loss: 1.2066 - val_accuracy: 0.8479\n",
      "Epoch 392/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0563 - accuracy: 0.9820 - val_loss: 1.1404 - val_accuracy: 0.8460\n",
      "Epoch 393/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0533 - accuracy: 0.9839 - val_loss: 1.2159 - val_accuracy: 0.8517\n",
      "Epoch 394/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0526 - accuracy: 0.9834 - val_loss: 1.1264 - val_accuracy: 0.8491\n",
      "Epoch 395/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0514 - accuracy: 0.9824 - val_loss: 1.0847 - val_accuracy: 0.8479\n",
      "Epoch 396/500\n",
      "37/36 [==============================] - 3s 94ms/step - loss: 0.0593 - accuracy: 0.9841 - val_loss: 1.1102 - val_accuracy: 0.8453\n",
      "Epoch 397/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0457 - accuracy: 0.9864 - val_loss: 1.0594 - val_accuracy: 0.8479\n",
      "Epoch 398/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.0388 - accuracy: 0.9858 - val_loss: 1.1597 - val_accuracy: 0.8453\n",
      "Epoch 399/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0476 - accuracy: 0.9851 - val_loss: 1.1471 - val_accuracy: 0.8434\n",
      "Epoch 400/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.0508 - accuracy: 0.9841 - val_loss: 1.0533 - val_accuracy: 0.8466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/500\n",
      "37/36 [==============================] - 4s 102ms/step - loss: 0.0501 - accuracy: 0.9841 - val_loss: 1.1298 - val_accuracy: 0.8447\n",
      "Epoch 402/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.0613 - accuracy: 0.9790 - val_loss: 1.0420 - val_accuracy: 0.8402\n",
      "Epoch 403/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0609 - accuracy: 0.9807 - val_loss: 1.1107 - val_accuracy: 0.8472\n",
      "Epoch 404/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0567 - accuracy: 0.9826 - val_loss: 1.1375 - val_accuracy: 0.8428\n",
      "Epoch 405/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.0525 - accuracy: 0.9851 - val_loss: 1.0312 - val_accuracy: 0.8479\n",
      "Epoch 406/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.0516 - accuracy: 0.9832 - val_loss: 1.0682 - val_accuracy: 0.8485\n",
      "Epoch 407/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.0504 - accuracy: 0.9847 - val_loss: 1.0880 - val_accuracy: 0.8453\n",
      "Epoch 408/500\n",
      "37/36 [==============================] - 3s 94ms/step - loss: 0.0630 - accuracy: 0.9807 - val_loss: 1.0308 - val_accuracy: 0.8466\n",
      "Epoch 409/500\n",
      " 3/36 [=>............................] - ETA: 4s - loss: 0.0252 - accuracy: 0.9870"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.135960). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/36 [==============================] - 3s 93ms/step - loss: 0.0422 - accuracy: 0.9851 - val_loss: 1.0674 - val_accuracy: 0.8549\n",
      "Epoch 410/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0504 - accuracy: 0.9839 - val_loss: 1.0651 - val_accuracy: 0.8428\n",
      "Epoch 411/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0415 - accuracy: 0.9862 - val_loss: 1.0618 - val_accuracy: 0.8453\n",
      "Epoch 412/500\n",
      "37/36 [==============================] - 3s 81ms/step - loss: 0.0476 - accuracy: 0.9824 - val_loss: 1.1143 - val_accuracy: 0.8517\n",
      "Epoch 413/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.0444 - accuracy: 0.9845 - val_loss: 1.0140 - val_accuracy: 0.8460\n",
      "Epoch 414/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0431 - accuracy: 0.9888 - val_loss: 1.1653 - val_accuracy: 0.8530\n",
      "Epoch 415/500\n",
      "37/36 [==============================] - 4s 115ms/step - loss: 0.0504 - accuracy: 0.9820 - val_loss: 1.0173 - val_accuracy: 0.8498\n",
      "Epoch 416/500\n",
      "37/36 [==============================] - 4s 97ms/step - loss: 0.0420 - accuracy: 0.9866 - val_loss: 1.1226 - val_accuracy: 0.8472\n",
      "Epoch 417/500\n",
      "37/36 [==============================] - 4s 102ms/step - loss: 0.0517 - accuracy: 0.9837 - val_loss: 1.1301 - val_accuracy: 0.8434\n",
      "Epoch 418/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0494 - accuracy: 0.9868 - val_loss: 0.9994 - val_accuracy: 0.8523\n",
      "Epoch 419/500\n",
      "37/36 [==============================] - 3s 81ms/step - loss: 0.0450 - accuracy: 0.9849 - val_loss: 1.0816 - val_accuracy: 0.8447\n",
      "Epoch 420/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0443 - accuracy: 0.9854 - val_loss: 1.0642 - val_accuracy: 0.8491\n",
      "Epoch 421/500\n",
      "37/36 [==============================] - 3s 91ms/step - loss: 0.0424 - accuracy: 0.9875 - val_loss: 1.1332 - val_accuracy: 0.8466\n",
      "Epoch 422/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.0426 - accuracy: 0.9866 - val_loss: 1.1499 - val_accuracy: 0.8460\n",
      "Epoch 423/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0442 - accuracy: 0.9862 - val_loss: 1.1968 - val_accuracy: 0.8479\n",
      "Epoch 424/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0457 - accuracy: 0.9866 - val_loss: 1.1245 - val_accuracy: 0.8491\n",
      "Epoch 425/500\n",
      "37/36 [==============================] - 4s 100ms/step - loss: 0.0366 - accuracy: 0.9883 - val_loss: 1.1954 - val_accuracy: 0.8466\n",
      "Epoch 426/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0477 - accuracy: 0.9830 - val_loss: 0.9744 - val_accuracy: 0.8479\n",
      "Epoch 427/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0492 - accuracy: 0.9851 - val_loss: 1.1086 - val_accuracy: 0.8491\n",
      "Epoch 428/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0395 - accuracy: 0.9858 - val_loss: 1.1819 - val_accuracy: 0.8523\n",
      "Epoch 429/500\n",
      "37/36 [==============================] - 3s 79ms/step - loss: 0.0458 - accuracy: 0.9841 - val_loss: 1.1060 - val_accuracy: 0.8549\n",
      "Epoch 430/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0415 - accuracy: 0.9875 - val_loss: 1.1807 - val_accuracy: 0.8479\n",
      "Epoch 431/500\n",
      "37/36 [==============================] - 3s 90ms/step - loss: 0.0444 - accuracy: 0.9847 - val_loss: 1.1373 - val_accuracy: 0.8460\n",
      "Epoch 432/500\n",
      "37/36 [==============================] - 3s 79ms/step - loss: 0.0444 - accuracy: 0.9841 - val_loss: 1.1637 - val_accuracy: 0.8542\n",
      "Epoch 433/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0506 - accuracy: 0.9847 - val_loss: 1.1679 - val_accuracy: 0.8485\n",
      "Epoch 434/500\n",
      "37/36 [==============================] - 4s 98ms/step - loss: 0.0559 - accuracy: 0.9822 - val_loss: 1.0691 - val_accuracy: 0.8542\n",
      "Epoch 435/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0442 - accuracy: 0.9856 - val_loss: 1.0905 - val_accuracy: 0.8517\n",
      "Epoch 436/500\n",
      "37/36 [==============================] - 3s 81ms/step - loss: 0.0525 - accuracy: 0.9841 - val_loss: 1.0383 - val_accuracy: 0.8568\n",
      "Epoch 437/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0497 - accuracy: 0.9837 - val_loss: 1.1810 - val_accuracy: 0.8542\n",
      "Epoch 438/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0402 - accuracy: 0.9868 - val_loss: 1.0859 - val_accuracy: 0.8491\n",
      "Epoch 439/500\n",
      "37/36 [==============================] - 4s 101ms/step - loss: 0.0492 - accuracy: 0.9849 - val_loss: 1.1008 - val_accuracy: 0.8460\n",
      "Epoch 440/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.0529 - accuracy: 0.9851 - val_loss: 1.0895 - val_accuracy: 0.8523\n",
      "Epoch 441/500\n",
      "37/36 [==============================] - 4s 96ms/step - loss: 0.0448 - accuracy: 0.9847 - val_loss: 1.0916 - val_accuracy: 0.8530\n",
      "Epoch 442/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.0499 - accuracy: 0.9843 - val_loss: 1.0848 - val_accuracy: 0.8530\n",
      "Epoch 443/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0552 - accuracy: 0.9837 - val_loss: 1.1075 - val_accuracy: 0.8453\n",
      "Epoch 444/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0475 - accuracy: 0.9851 - val_loss: 1.0732 - val_accuracy: 0.8517\n",
      "Epoch 445/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0404 - accuracy: 0.9877 - val_loss: 1.1218 - val_accuracy: 0.8555\n",
      "Epoch 446/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0414 - accuracy: 0.9849 - val_loss: 1.0652 - val_accuracy: 0.8498\n",
      "Epoch 447/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0533 - accuracy: 0.9826 - val_loss: 1.1045 - val_accuracy: 0.8428\n",
      "Epoch 448/500\n",
      "37/36 [==============================] - 4s 99ms/step - loss: 0.0432 - accuracy: 0.9849 - val_loss: 1.0956 - val_accuracy: 0.8523\n",
      "Epoch 449/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0415 - accuracy: 0.9871 - val_loss: 1.1345 - val_accuracy: 0.8511\n",
      "Epoch 450/500\n",
      "37/36 [==============================] - 3s 81ms/step - loss: 0.0478 - accuracy: 0.9883 - val_loss: 1.1400 - val_accuracy: 0.8479\n",
      "Epoch 451/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.0543 - accuracy: 0.9822 - val_loss: 1.1450 - val_accuracy: 0.8440\n",
      "Epoch 452/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0322 - accuracy: 0.9888 - val_loss: 1.1546 - val_accuracy: 0.8491\n",
      "Epoch 453/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0406 - accuracy: 0.9871 - val_loss: 1.2189 - val_accuracy: 0.8434\n",
      "Epoch 454/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0565 - accuracy: 0.9851 - val_loss: 1.0980 - val_accuracy: 0.8415\n",
      "Epoch 455/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0382 - accuracy: 0.9881 - val_loss: 1.1893 - val_accuracy: 0.8421\n",
      "Epoch 456/500\n",
      "37/36 [==============================] - 3s 81ms/step - loss: 0.0369 - accuracy: 0.9866 - val_loss: 1.2082 - val_accuracy: 0.8491\n",
      "Epoch 457/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.0503 - accuracy: 0.9851 - val_loss: 1.1313 - val_accuracy: 0.8447\n",
      "Epoch 458/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0396 - accuracy: 0.9866 - val_loss: 1.1117 - val_accuracy: 0.8434\n",
      "Epoch 459/500\n",
      "37/36 [==============================] - 3s 80ms/step - loss: 0.0499 - accuracy: 0.9843 - val_loss: 1.1152 - val_accuracy: 0.8421\n",
      "Epoch 460/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0416 - accuracy: 0.9860 - val_loss: 1.1898 - val_accuracy: 0.8504\n",
      "Epoch 461/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.0439 - accuracy: 0.9849 - val_loss: 1.2266 - val_accuracy: 0.8485\n",
      "Epoch 462/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0438 - accuracy: 0.9877 - val_loss: 1.1769 - val_accuracy: 0.8530\n",
      "Epoch 463/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0427 - accuracy: 0.9877 - val_loss: 1.1430 - val_accuracy: 0.8511\n",
      "Epoch 464/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0394 - accuracy: 0.9866 - val_loss: 1.2571 - val_accuracy: 0.8460\n",
      "Epoch 465/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.0482 - accuracy: 0.9858 - val_loss: 1.1449 - val_accuracy: 0.8491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0332 - accuracy: 0.9875 - val_loss: 1.2216 - val_accuracy: 0.8555\n",
      "Epoch 467/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.0331 - accuracy: 0.9898 - val_loss: 1.3437 - val_accuracy: 0.8536\n",
      "Epoch 468/500\n",
      "37/36 [==============================] - 4s 102ms/step - loss: 0.0389 - accuracy: 0.9871 - val_loss: 1.0896 - val_accuracy: 0.8485\n",
      "Epoch 469/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0392 - accuracy: 0.9877 - val_loss: 1.1336 - val_accuracy: 0.8358\n",
      "Epoch 470/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0397 - accuracy: 0.9871 - val_loss: 1.1479 - val_accuracy: 0.8453\n",
      "Epoch 471/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0410 - accuracy: 0.9868 - val_loss: 1.1589 - val_accuracy: 0.8447\n",
      "Epoch 472/500\n",
      "37/36 [==============================] - 3s 79ms/step - loss: 0.0390 - accuracy: 0.9854 - val_loss: 1.1617 - val_accuracy: 0.8504\n",
      "Epoch 473/500\n",
      "37/36 [==============================] - 3s 85ms/step - loss: 0.0457 - accuracy: 0.9847 - val_loss: 1.2472 - val_accuracy: 0.8574\n",
      "Epoch 474/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0515 - accuracy: 0.9826 - val_loss: 1.2602 - val_accuracy: 0.8460\n",
      "Epoch 475/500\n",
      "37/36 [==============================] - 3s 79ms/step - loss: 0.0512 - accuracy: 0.9854 - val_loss: 1.1950 - val_accuracy: 0.8530\n",
      "Epoch 476/500\n",
      "37/36 [==============================] - 3s 89ms/step - loss: 0.0473 - accuracy: 0.9858 - val_loss: 1.1289 - val_accuracy: 0.8472\n",
      "Epoch 477/500\n",
      "37/36 [==============================] - 3s 94ms/step - loss: 0.0475 - accuracy: 0.9849 - val_loss: 1.0416 - val_accuracy: 0.8517\n",
      "Epoch 478/500\n",
      "37/36 [==============================] - 4s 100ms/step - loss: 0.0396 - accuracy: 0.9871 - val_loss: 1.2309 - val_accuracy: 0.8345\n",
      "Epoch 479/500\n",
      "37/36 [==============================] - 4s 106ms/step - loss: 0.0308 - accuracy: 0.9896 - val_loss: 1.1550 - val_accuracy: 0.8472\n",
      "Epoch 480/500\n",
      "37/36 [==============================] - 3s 93ms/step - loss: 0.0369 - accuracy: 0.9875 - val_loss: 1.2416 - val_accuracy: 0.8460\n",
      "Epoch 481/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0403 - accuracy: 0.9858 - val_loss: 1.1374 - val_accuracy: 0.8409\n",
      "Epoch 482/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0457 - accuracy: 0.9843 - val_loss: 1.2643 - val_accuracy: 0.8402\n",
      "Epoch 483/500\n",
      "37/36 [==============================] - 3s 86ms/step - loss: 0.0447 - accuracy: 0.9860 - val_loss: 1.1876 - val_accuracy: 0.8409\n",
      "Epoch 484/500\n",
      "37/36 [==============================] - 3s 94ms/step - loss: 0.0424 - accuracy: 0.9854 - val_loss: 1.2198 - val_accuracy: 0.8472\n",
      "Epoch 485/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0367 - accuracy: 0.9862 - val_loss: 1.2669 - val_accuracy: 0.8440\n",
      "Epoch 486/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0348 - accuracy: 0.9888 - val_loss: 1.3857 - val_accuracy: 0.8479\n",
      "Epoch 487/500\n",
      "37/36 [==============================] - 4s 100ms/step - loss: 0.0447 - accuracy: 0.9868 - val_loss: 1.2754 - val_accuracy: 0.8472\n",
      "Epoch 488/500\n",
      "37/36 [==============================] - 3s 83ms/step - loss: 0.0423 - accuracy: 0.9879 - val_loss: 1.1804 - val_accuracy: 0.8466\n",
      "Epoch 489/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0428 - accuracy: 0.9843 - val_loss: 1.1426 - val_accuracy: 0.8453\n",
      "Epoch 490/500\n",
      "37/36 [==============================] - 3s 88ms/step - loss: 0.0499 - accuracy: 0.9871 - val_loss: 1.0541 - val_accuracy: 0.8511\n",
      "Epoch 491/500\n",
      "37/36 [==============================] - 4s 101ms/step - loss: 0.0370 - accuracy: 0.9871 - val_loss: 1.1472 - val_accuracy: 0.8447\n",
      "Epoch 492/500\n",
      "37/36 [==============================] - 3s 81ms/step - loss: 0.0354 - accuracy: 0.9883 - val_loss: 1.1679 - val_accuracy: 0.8517\n",
      "Epoch 493/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0371 - accuracy: 0.9873 - val_loss: 1.2298 - val_accuracy: 0.8479\n",
      "Epoch 494/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0372 - accuracy: 0.9864 - val_loss: 1.1878 - val_accuracy: 0.8491\n",
      "Epoch 495/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0649 - accuracy: 0.9832 - val_loss: 1.0833 - val_accuracy: 0.8568\n",
      "Epoch 496/500\n",
      "37/36 [==============================] - 3s 87ms/step - loss: 0.0342 - accuracy: 0.9885 - val_loss: 1.1767 - val_accuracy: 0.8485\n",
      "Epoch 497/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.0407 - accuracy: 0.9864 - val_loss: 1.1812 - val_accuracy: 0.8460\n",
      "Epoch 498/500\n",
      "37/36 [==============================] - 3s 82ms/step - loss: 0.0398 - accuracy: 0.9888 - val_loss: 1.2378 - val_accuracy: 0.8498\n",
      "Epoch 499/500\n",
      "37/36 [==============================] - 3s 84ms/step - loss: 0.0521 - accuracy: 0.9854 - val_loss: 1.1792 - val_accuracy: 0.8390\n",
      "Epoch 500/500\n",
      "37/36 [==============================] - 3s 92ms/step - loss: 0.0388 - accuracy: 0.9854 - val_loss: 1.2286 - val_accuracy: 0.8485\n"
     ]
    }
   ],
   "source": [
    "### 模型訓練學習 ###\n",
    "\n",
    "# 首先使用AdaDelta來做第一階段的訓練, 因為AdaMax會無卡住\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adadelta',  \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 進行20循環就足夠了\n",
    "model.fit(X_train, Y_train, batch_size=batch_size,\n",
    "                    epochs=20, \n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "# 接著改用AdaMax\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adamax',  \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# 我們想要保存在訓練過程中驗證結果比較好的模型\n",
    "\n",
    "# 在訓練的過程透過ImageDataGenerator來持續產生圖像資料\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(X_train)/batch_size,\n",
    "                    epochs=nb_epoch, \n",
    "                    validation_data=(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 進行預測 ###\n",
    "\n",
    "# 載入Kaggle測試資料集\n",
    "X_test = np.load(path+\"/testPreproc.npy\")\n",
    "\n",
    "# 預測字符的類別\n",
    "Y_test_pred = model.predict_classes(X_test)\n",
    "\n",
    "# 從類別的數字轉換為字符\n",
    "vInt2label = np.vectorize(int2label)\n",
    "Y_test_pred = vInt2label(Y_test_pred) \n",
    "\n",
    "# 保存預測結果到檔案系統\n",
    "np.savetxt(path+\"/jular_pred\" + \".csv\", np.c_[range(6284,len(Y_test_pred)+6284),Y_test_pred], delimiter=',', header = 'ID,Class', comments = '', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 透過趨勢圖來觀察訓練與驗證的走向 (特別去觀察是否有\"過擬合(overfitting)\"的現象)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 把每個訓練循環(epochs)的相關重要的監控指標取出來\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# 取得整個訓練循環(epochs)的總次數\n",
    "epochs = range(len(acc))\n",
    "\n",
    "# 把\"訓練準確率(Training acc)\"與\"驗證準確率(Validation acc)\"的趨勢線形表現在圖表上\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# 把\"訓練損失(Training loss)\"與\"驗證損失(Validation loss)\"的趨勢線形表現在圖表上\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Class'] = Y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
