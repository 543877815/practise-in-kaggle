{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/fashionmnist/t10k-labels-idx1-ubyte\n/kaggle/input/fashionmnist/train-labels-idx1-ubyte\n/kaggle/input/fashionmnist/train-images-idx3-ubyte\n/kaggle/input/fashionmnist/fashion-mnist_test.csv\n/kaggle/input/fashionmnist/fashion-mnist_train.csv\n/kaggle/input/fashionmnist/t10k-images-idx3-ubyte\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 資料預處理 (Data Preprocessing)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# 載入資料\ndata_train = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_train.csv')\ndata_test = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_test.csv')\n\nnum_classes = 10 # 標籤總共有10類\nimg_rows, img_cols, img_channels = 28, 28, 1 # 圖像是 28像素 x 28像素 (灰階: 1)\ninput_shape = (img_rows, img_cols, img_channels) # (圖像的height, 圖像的width, 圖像的顏色通道數channel)\n\nX = np.array(data_train.iloc[:, 1:]) # Dataframe中 idx(1 ~ 784)的欄都是像素值\n\n# 進行標籤的one-hot編碼\ny = to_categorical(np.array(data_train.iloc[:, 0])) # Dataframe 中 idx(0)的欄是標籤\n\n# 把訓練資料進行拆分成訓練(80%)與驗證(20%)資料集\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n\n# 測試資料的處理\nX_test = np.array(data_test.iloc[:, 1:])\ny_test = to_categorical(np.array(data_test.iloc[:, 0]))\n\n# 對向量進行shape的轉換以符合訓練的input要求\nX_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\nX_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\nX_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n\n# 對每個像素進行型別轉換與歸一化\nX_train = X_train.astype('float32')/255\nX_test = X_test.astype('float32')/255\nX_val = X_val.astype('float32')/255","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"## 網絡模型 (Model)構建"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\ndef create_model_six_conv(input_shape):\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', kernel_initializer='he_normal', input_shape=input_shape))\n    model.add(Conv2D(32, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n    \n    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n    \n    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n    \n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(num_classes, activation='softmax'))\n    \n    return model;","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam\n\nbatch_size = 256\nepochs = 50\n\n#圖像的shape是 (28,28,1)\nmodel = create_model_six_conv((img_rows, img_cols, img_channels)) # 初始化一個模型\n\n# 秀出模型架構\nmodel.summary() \n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adam(),\n              metrics=['accuracy'])","execution_count":4,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 26, 26, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 13, 13, 32)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 13, 13, 64)        18496     \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 11, 11, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 5, 5, 64)          0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 5, 5, 128)         73856     \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 3, 3, 128)         147584    \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 1, 1, 128)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 304,234\nTrainable params: 304,234\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 訓練 (Training)"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(X_val, y_val))","execution_count":5,"outputs":[{"output_type":"stream","text":"Train on 48000 samples, validate on 12000 samples\nEpoch 1/50\n48000/48000 [==============================] - 7s 140us/step - loss: 0.9266 - accuracy: 0.6553 - val_loss: 0.5044 - val_accuracy: 0.8069\nEpoch 2/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.5088 - accuracy: 0.8154 - val_loss: 0.3919 - val_accuracy: 0.8514\nEpoch 3/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.4141 - accuracy: 0.8498 - val_loss: 0.3300 - val_accuracy: 0.8777\nEpoch 4/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.3586 - accuracy: 0.8725 - val_loss: 0.2989 - val_accuracy: 0.8895\nEpoch 5/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.3305 - accuracy: 0.8830 - val_loss: 0.3019 - val_accuracy: 0.8898\nEpoch 6/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.3056 - accuracy: 0.8924 - val_loss: 0.2633 - val_accuracy: 0.9038\nEpoch 7/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.2848 - accuracy: 0.8982 - val_loss: 0.2576 - val_accuracy: 0.9043\nEpoch 8/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.2608 - accuracy: 0.9055 - val_loss: 0.2529 - val_accuracy: 0.9064\nEpoch 9/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.2500 - accuracy: 0.9110 - val_loss: 0.2410 - val_accuracy: 0.9089\nEpoch 10/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.2423 - accuracy: 0.9128 - val_loss: 0.2406 - val_accuracy: 0.9119\nEpoch 11/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.2262 - accuracy: 0.9188 - val_loss: 0.2255 - val_accuracy: 0.9160\nEpoch 12/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.2177 - accuracy: 0.9209 - val_loss: 0.2169 - val_accuracy: 0.9203\nEpoch 13/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.2109 - accuracy: 0.9252 - val_loss: 0.2246 - val_accuracy: 0.9170\nEpoch 14/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.2070 - accuracy: 0.9262 - val_loss: 0.2175 - val_accuracy: 0.9172\nEpoch 15/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.1898 - accuracy: 0.9305 - val_loss: 0.2261 - val_accuracy: 0.9164\nEpoch 16/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.1871 - accuracy: 0.9316 - val_loss: 0.2124 - val_accuracy: 0.9251\nEpoch 17/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.1781 - accuracy: 0.9346 - val_loss: 0.2077 - val_accuracy: 0.9242\nEpoch 18/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.1680 - accuracy: 0.9391 - val_loss: 0.2185 - val_accuracy: 0.9262\nEpoch 19/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.1665 - accuracy: 0.9401 - val_loss: 0.2183 - val_accuracy: 0.9235\nEpoch 20/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.1622 - accuracy: 0.9404 - val_loss: 0.2173 - val_accuracy: 0.9239\nEpoch 21/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.1549 - accuracy: 0.9420 - val_loss: 0.2117 - val_accuracy: 0.9293\nEpoch 22/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.1513 - accuracy: 0.9442 - val_loss: 0.2063 - val_accuracy: 0.9282\nEpoch 23/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.1417 - accuracy: 0.9481 - val_loss: 0.2152 - val_accuracy: 0.9289\nEpoch 24/50\n48000/48000 [==============================] - 3s 59us/step - loss: 0.1429 - accuracy: 0.9465 - val_loss: 0.2178 - val_accuracy: 0.9285\nEpoch 25/50\n48000/48000 [==============================] - 3s 59us/step - loss: 0.1384 - accuracy: 0.9493 - val_loss: 0.2102 - val_accuracy: 0.9315\nEpoch 26/50\n48000/48000 [==============================] - 3s 59us/step - loss: 0.1335 - accuracy: 0.9515 - val_loss: 0.2281 - val_accuracy: 0.9258\nEpoch 27/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.1294 - accuracy: 0.9526 - val_loss: 0.2168 - val_accuracy: 0.9264\nEpoch 28/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.1259 - accuracy: 0.9530 - val_loss: 0.2161 - val_accuracy: 0.9307\nEpoch 29/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.1217 - accuracy: 0.9564 - val_loss: 0.2284 - val_accuracy: 0.9283\nEpoch 30/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.1196 - accuracy: 0.9567 - val_loss: 0.2356 - val_accuracy: 0.9284\nEpoch 31/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.1157 - accuracy: 0.9575 - val_loss: 0.2282 - val_accuracy: 0.9284\nEpoch 32/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.1108 - accuracy: 0.9596 - val_loss: 0.2576 - val_accuracy: 0.9271\nEpoch 33/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.1084 - accuracy: 0.9599 - val_loss: 0.2400 - val_accuracy: 0.9251\nEpoch 34/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.1070 - accuracy: 0.9615 - val_loss: 0.2275 - val_accuracy: 0.9306\nEpoch 35/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.1053 - accuracy: 0.9607 - val_loss: 0.2355 - val_accuracy: 0.9285\nEpoch 36/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.1024 - accuracy: 0.9623 - val_loss: 0.2412 - val_accuracy: 0.9275\nEpoch 37/50\n48000/48000 [==============================] - 3s 58us/step - loss: 0.1031 - accuracy: 0.9622 - val_loss: 0.2358 - val_accuracy: 0.9284\nEpoch 38/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.0960 - accuracy: 0.9651 - val_loss: 0.2491 - val_accuracy: 0.9283\nEpoch 39/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.0972 - accuracy: 0.9642 - val_loss: 0.2509 - val_accuracy: 0.9272\nEpoch 40/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.0947 - accuracy: 0.9653 - val_loss: 0.2352 - val_accuracy: 0.9302\nEpoch 41/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.0885 - accuracy: 0.9682 - val_loss: 0.2530 - val_accuracy: 0.9258\nEpoch 42/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.0901 - accuracy: 0.9672 - val_loss: 0.2479 - val_accuracy: 0.9287\nEpoch 43/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.0916 - accuracy: 0.9670 - val_loss: 0.2496 - val_accuracy: 0.9281\nEpoch 44/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.0841 - accuracy: 0.9689 - val_loss: 0.2610 - val_accuracy: 0.9288\nEpoch 45/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.0840 - accuracy: 0.9696 - val_loss: 0.2572 - val_accuracy: 0.9298\nEpoch 46/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.0826 - accuracy: 0.9699 - val_loss: 0.2617 - val_accuracy: 0.9280\nEpoch 47/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.0821 - accuracy: 0.9693 - val_loss: 0.2708 - val_accuracy: 0.9261\nEpoch 48/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.0806 - accuracy: 0.9709 - val_loss: 0.2705 - val_accuracy: 0.9265\nEpoch 49/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.0805 - accuracy: 0.9705 - val_loss: 0.2700 - val_accuracy: 0.9290\nEpoch 50/50\n48000/48000 [==============================] - 3s 57us/step - loss: 0.0766 - accuracy: 0.9715 - val_loss: 0.2627 - val_accuracy: 0.9277\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 訓練過程的可視化"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 透過趨勢圖來觀察訓練與驗證的走向 (特別去觀察是否有\"過擬合(overfitting)\"的現象)\nimport matplotlib.pyplot as plt\n\ndef plot_train_history(history, train_metrics, val_metrics):\n    plt.plot(history.history.get(train_metrics),'-o')\n    plt.plot(history.history.get(val_metrics),'-o')\n    plt.ylabel(train_metrics)\n    plt.xlabel('Epochs')\n    plt.legend(['train', 'validation'])\n    \n    \nplt.figure(figsize=(12,4))\nplt.subplot(1,2,1)\nplot_train_history(history, 'loss','val_loss')\n\nplt.subplot(1,2,2)\nplot_train_history(history, 'accuracy','val_accuracy')\n\nplt.show()","execution_count":6,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"x, y, and format string must not be None","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-21d5e1b430c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mplot_train_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-21d5e1b430c9>\u001b[0m in \u001b[0;36mplot_train_history\u001b[0;34m(history, train_metrics, val_metrics)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_train_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2809\u001b[0m     return gca().plot(\n\u001b[1;32m   2810\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2811\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;31m# downstream.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x, y, and format string must not be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: x, y, and format string must not be None"]},{"output_type":"display_data","data":{"text/plain":"<Figure size 864x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"## 驗證評估 (Evaluation) "},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(X_test, y_test, verbose=0)\n\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 每一種類別的預測正確率"},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the predictions for the test data\npredicted_classes = model.predict_classes(X_test)\n\n#get the indices to be plotted\ny_true = data_test.iloc[:, 0]\ncorrects = np.nonzero(predicted_classes==y_true)[0]\nincorrects = np.nonzero(predicted_classes!=y_true)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ntarget_names = [\"Class {}\".format(i) for i in range(num_classes)]\nprint(classification_report(y_true, predicted_classes, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 正確辨識的圖像範例:"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, correct in enumerate(corrects[:9]):\n    plt.subplot(3,3,i+1)\n    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_true[correct]))\n    plt.tight_layout()\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 辨識錯誤的圖像範例"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, incorrect in enumerate(incorrects[0:9]):\n    plt.subplot(3,3,i+1)\n    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_true[incorrect]))\n    plt.tight_layout()\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}